{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1bU7GhF23xWvpCyve3p8sX7aqbg235nCJ",
      "authorship_tag": "ABX9TyNELW74gDBfEJE9jj5x1/7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakibulhaque9954/Machine_Learning_Translation/blob/main/Machine_translation_Bahdanau_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgement"
      ],
      "metadata": {
        "id": "VGgjjqp2_ZzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on research by Dzmitry Bahdanau**<br>\n",
        "Paper Link: https://arxiv.org/pdf/1409.0473.pdf\n"
      ],
      "metadata": {
        "id": "Ojkq8lGs_ezj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "YkeasEue5qIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vt93_FwG0cLc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "yHoYbLZ0Vd1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Download"
      ],
      "metadata": {
        "id": "pHsvMYjUVhzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntrhZXbqVhU0",
        "outputId": "57ae5e51-ec47-4ae2-9e03-c5410ca452fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-22 07:43:06--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7757635 (7.4M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.40M  4.27MB/s    in 1.7s    \n",
            "\n",
            "2023-10-22 07:43:09 (4.27 MB/s) - ‘fra-eng.zip’ saved [7757635/7757635]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ogDgWojVmgW",
        "outputId": "22993790-31e4-4196-8abe-741a849bdb02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "496hge3MVqfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_dataset = tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"
      ],
      "metadata": {
        "id": "8PTxBVhRVtHn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 20000\n",
        "ENGLISH_SEQUENCE_LENGTH = 64\n",
        "FRENCH_SEQUENCE_LENGTH = 64\n",
        "EMBEDDING_DIM = 300\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "BdHMIIBUVwk1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_vectorize_layer = TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "FWKfvKc0VyZP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_vectorize_layer = TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ],
      "metadata": {
        "id": "1Pxg86h3Vz4T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selector(input_text):\n",
        "  split_text = tf.strings.split(input_text,'\\t')\n",
        "  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "cuF4bBn0V1wG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = text_dataset.map(selector)"
      ],
      "metadata": {
        "id": "XyqsU18hV2hl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separator(input_text):\n",
        "  split_text = tf.strings.split(input_text,'\\t')\n",
        "  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"
      ],
      "metadata": {
        "id": "qCv6PgKNV35i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_dataset = text_dataset.map(separator)"
      ],
      "metadata": {
        "id": "JrPDAYWZV6Uh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju_kmPLLV7yR",
        "outputId": "94921066-31db-4415-8ac5-be55bf6b57af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary Creation"
      ],
      "metadata": {
        "id": "Poh42v6PV-Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_training_data=init_dataset.map(lambda x,y:x) # input x,y and output x\n",
        "english_vectorize_layer.adapt(english_training_data) # adapt the vectorize_layer to the training data\n",
        "\n",
        "french_training_data=init_dataset.map(lambda x,y:y) # input x,y,z and output y\n",
        "french_vectorize_layer.adapt(french_training_data) # adapt the vectorize_layer to the training data"
      ],
      "metadata": {
        "id": "foghUS5HWA-3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grouping and Vectorizing for training"
      ],
      "metadata": {
        "id": "K57EhISUWIOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizer(inputs,output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"
      ],
      "metadata": {
        "id": "HnCwIX7hWG3J"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8iZo8VWWNvw",
        "outputId": "c442e711-e131-4cd4-c184-b0f0492915fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=split_dataset.map(vectorizer)"
      ],
      "metadata": {
        "id": "AbOPWonzWPxb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in split_dataset.take(3):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ9c340xWRh7",
        "outputId": "31d249f5-87cc-42e9-e04a-4e8e94b7793f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Va !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken Marche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttoken En route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObbndISGWSCO",
        "outputId": "30842e43-c75e-4429-fdfe-9bcd0caf2d20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[  2, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>}, <tf.Tensor: shape=(1, 64), dtype=int64, numpy=\n",
            "array([[103,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HegZ8trWVtu",
        "outputId": "18bc7219-8e5e-4c61-a8bc-17d35d7b3885"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "lf8z62zYWXtt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmcfGjPHWjRW",
        "outputId": "b3d24b46-cc68-4ac2-9db7-d799c109bf4d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_BATCHES = int(200000/BATCH_SIZE)"
      ],
      "metadata": {
        "id": "CC75EqgIWlgD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Split"
      ],
      "metadata": {
        "id": "h4W-wmztWnpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset = dataset.skip(int(0.9*NUM_BATCHES))"
      ],
      "metadata": {
        "id": "sE3NStdoWm9G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtyT8GVvWrgL",
        "outputId": "c6f9b2cc-8ce0-4677-ba80-ea9b205da825"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_1': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None), 'input_2': TensorSpec(shape=(None, 64), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 64), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "<hr>\n",
        "<h4>Model Architecture</h4>\n",
        "<hr>\n",
        "<img src='https://www.researchgate.net/publication/330924206/figure/fig2/AS:723516190121985@1549511110958/Architecture-of-RNNsearch-Bahdanau-et-al-2015-left-and-its-attention-model-right.jpg'>"
      ],
      "metadata": {
        "id": "xrvBxtH4XDVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Step Wise Explanation:***\n",
        "<br>\n",
        "Bahdanau mechanisms help the model decide which parts of the source sentence to pay attention to while generating the corresponding words in the target language. Here's a simplified overview:\n",
        "\n",
        "- Encoder-Decoder Architecture: The neural network used for translation consists of two main parts: the encoder and the decoder. The encoder processes the input sentence, creating a hidden representation that captures the meaning of the sentence. Think of it as encoding the source language's information.\n",
        "- Attention Mechanism: The attention mechanism, which Bahdanau introduced. It allows the model to focus on specific parts of the input sentence while generating each word in the output sentence. can be imagined as a spotlight that helps the model decide where to look while translating.\n",
        "- Alignment Scores: For each word in the target sentence, the model calculates alignment scores for each word in the source sentence. These scores indicate how relevant each word in the source sentence is to generating the current word in the target sentence.\n",
        "- Softmax and Weighted Sum: The alignment scores go through a softmax function to turn them into probabilities. This ensures that the model gives more attention to words with higher scores. The weighted sum of the encoder's hidden states, using these probabilities, is used as context information for generating the current target word.\n",
        "- Generating Output: The decoder, armed with this context information, generates the next word in the target sentence. It does this one word at a time, using the previously generated words as input.\n",
        "- Repeat and Refine: The process repeats for each word in the target sentence, with the decoder updating its internal state based on the previously generated words.\n",
        "- End of Sentence: The model generates words until it predicts an end-of-sentence token or reaches a predefined maximum length for the translation."
      ],
      "metadata": {
        "id": "lk0tiCgG2EcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***More detailed overview of the Attention mechanism***\n",
        "<br>\n",
        "Let's use the example 'I love apples' sequence to better illustrate the process:\n",
        "\n",
        "1. **Encoding**:\n",
        "   - Each word in the input sentence \"I love apples\" is encoded into a vector by the encoder, resulting in vectors (v_I, v_{love}, v_{apples}).\n",
        "\n",
        "2. **Initialization**:\n",
        "   - The decoder starts with a start token, say `<START>`.\n",
        "\n",
        "3. **Attention Weights Calculation (1st Word)**:\n",
        "   - For translating the first word, attention weights are calculated based on the initial state of the decoder and each vector from the encoder.\n",
        "   - Let’s assume the raw attention scores are higher for the word \"I\", say (a = [0.7, 0.2, 0.1]) respectively for(v_I, v_{love}, v_{apples}).\n",
        "\n",
        "4. **Softmax Normalization (1st Word)**:\n",
        "   - Applying the softmax function to these scores: softmax(a) = [0.496, 0.247, 0.247]\\).\n",
        "\n",
        "5. **Context Vector Generation (1st Word)**:\n",
        "   - The context vector is then formed by the weighted sum of the encoder vectors:\n",
        "     context_1 = 0.496.v_I + 0.247.v_{love} + 0.247.v_{apples}.\n",
        "\n",
        "6. **Translation and Decoder Update (1st Word)**:\n",
        "   - This context vector, along with the decoder's state, is used to predict the first word in the French translation, \"J'\", and to update the decoder's state for the next word prediction.\n",
        "\n",
        "The process continues in a similar fashion for the remaining words, with attention weights reflecting the relevance of each word in the input sequence for the current word being translated in the output sequence. For instance, when translating \"aime\" (love), the attention weight should be higher for \"love\", and when translating \"les pommes\" (the apples), the attention weight should be higher for \"apples\". This way, the attention mechanism allows the model to focus on the relevant parts of the input sequence for each word in the translation, aiding in a more accurate and contextually grounded translation."
      ],
      "metadata": {
        "id": "5RwcocQc24xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bahdanau Architecture"
      ],
      "metadata": {
        "id": "hmPY5aUXXORJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "dqhsy5auXVnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, lstm_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.lstm_units = lstm_units\n",
        "\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "    self.lstm = LSTM(self.lstm_units, return_sequences=True) # returning each output from each block for subvectors attention\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "    output = self.lstm(x)\n",
        "    return output"
      ],
      "metadata": {
        "id": "nuKy3eBfXE-Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_UNITS = 256\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "encoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS)\n",
        "encoder_output = encoder(tf.zeros([128, 8])) # suppose pass an input of [batch_size, sequence_length]\n",
        "print(encoder_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdHdqE2WYzHU",
        "outputId": "03ead3e2-1222-4705-b70c-2666d56b2889"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 8, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bahdanau Attention Layer"
      ],
      "metadata": {
        "id": "0bMKbFcIZjVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.w_1 = Dense(self.units)\n",
        "    self.w_2 = Dense(self.units)\n",
        "    self.w = Dense(1)\n",
        "\n",
        "  def call(self, prev_decoder_state, encoder_states):\n",
        "    scores = self.w(\n",
        "        tf.nn.tanh(\n",
        "            self.w_1(tf.expand_dims(prev_decoder_state, -2)) +\n",
        "            self.w_2(encoder_states)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scores, axis=1)\n",
        "    context_vector = attention_weights * encoder_states\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) # condensing to one vector\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lO_zuL9xbIZW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_attention=BahdanauAttention(256)\n",
        "context_vector,attention_weights=bahdanau_attention(tf.zeros([128,32]),tf.zeros([128,8,32])) # Encoder states[batch_size, sequence_length, encoded_dims]\n",
        "print(context_vector.shape) # tf.reduce_sum operation is used to reduce the\n",
        "# dimensions along the sequence_length axis, effectively computing a weighted sum of the encoder_states\n",
        "print(attention_weights.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF6VccTCcEwZ",
        "outputId": "3279fe8a-dd0f-4528-ece4-7d582cbad2eb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 32)\n",
            "(128, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "mwY8O2xnk-d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, decoder_units, sequence_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.vocab_size = vocab_size\n",
        "    self.decoder_units = decoder_units\n",
        "    self.sequence_length = sequence_length\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.dense = Dense(self.vocab_size, activation='softmax')\n",
        "    self.gru = GRU(\n",
        "        self.decoder_units, return_sequences=True, return_state=True)\n",
        "    self.attention = BahdanauAttention(self.decoder_units)\n",
        "    self.embedding = Embedding(self.vocab_size, self.embedding_dim)\n",
        "\n",
        "  def call(self, x, hidden, shifted_target):\n",
        "    outputs = []\n",
        "    context_vectors = []\n",
        "    attention_weightss = []\n",
        "    shifted_target = self.embedding(shifted_target)\n",
        "\n",
        "    for t in range(0, self.sequence_length):\n",
        "      context_vector, attention_weights = self.attention(hidden, x) # Updated variable name to avoid conflict\n",
        "      decoder_input = context_vector + shifted_target[:, t]\n",
        "      output, hidden = self.gru(tf.expand_dims(decoder_input, 1)) # expanding dims\n",
        "      outputs.append(output[:, 0])\n",
        "\n",
        "    outputs = tf.convert_to_tensor(outputs)\n",
        "    # print(\"Shape of outputs before transpose:\", outputs.shape)\n",
        "    outputs = tf.transpose(outputs, perm=[1, 0, 2]) # permuted the positions of the outputs, basically just changing the shape\n",
        "\n",
        "    outputs = self.dense(outputs)\n",
        "\n",
        "    return outputs, attention_weights\n"
      ],
      "metadata": {
        "id": "UkpG3-lslB3R"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS, FRENCH_SEQUENCE_LENGTH)\n",
        "outputs,attention_weights = decoder(encoder_output, tf.zeros([128,HIDDEN_UNITS]),tf.zeros([128,64]))\n",
        "print(outputs.shape)\n",
        "print(attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VZz96c8cUnC",
        "outputId": "199a2a18-5751-4e26-b5d7-6233709a7ee4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 64, 20000)\n",
            "(128, 64, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Model"
      ],
      "metadata": {
        "id": "D1l831Exqv7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ENCODER ###\n",
        "input = Input(shape=(ENGLISH_SEQUENCE_LENGTH,), dtype='int64', name='input_1')\n",
        "encoder = Encoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS)\n",
        "encoder_output = encoder(input)\n",
        "\n",
        "### DECODER ###\n",
        "shifted_target = Input(shape=(FRENCH_SEQUENCE_LENGTH,), dtype='int64', name='input_2')\n",
        "decoder = Decoder(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_UNITS, FRENCH_SEQUENCE_LENGTH) # initializing initial state of decoder\n",
        "decoder_output, attention_weightss = decoder(encoder_output, tf.zeros([1, HIDDEN_UNITS]), shifted_target)\n",
        "\n",
        "### OUTPUT ###\n",
        "bahdanau_model = Model(inputs=[input, shifted_target], outputs=decoder_output)\n",
        "bahdanau_model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHQAwl21oYHK",
        "outputId": "065a56d8-cb25-4cd7-f76e-d79c78310304"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " encoder_8 (Encoder)         (None, 64, 256)              5645312   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " decoder_15 (Decoder)        ((None, 64, 20000),          1078659   ['encoder_8[0][0]',           \n",
            "                              (None, 64, 1))              3          'input_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16431905 (62.68 MB)\n",
            "Trainable params: 16431905 (62.68 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU Metric"
      ],
      "metadata": {
        "id": "tnXEaY5usBks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BLEU(tf.keras.metrics.Metric):\n",
        "    def __init__(self,name='bleu_score'):\n",
        "        super(BLEU,self).__init__()\n",
        "        self.bleu_score=0\n",
        "\n",
        "    def update_state(self,y_true,y_pred,sample_weight=None):\n",
        "      y_pred=tf.argmax(y_pred,-1)\n",
        "      self.bleu_score=0\n",
        "      for i,j in zip(y_pred,y_true):\n",
        "        tf.autograph.experimental.set_loop_options()\n",
        "\n",
        "        total_words=tf.math.count_nonzero(i)\n",
        "        total_matches=0\n",
        "        for word in i:\n",
        "          if word==0:\n",
        "            break\n",
        "          for q in range(len(j)):\n",
        "            if j[q]==0:\n",
        "              break\n",
        "            if word==j[q]:\n",
        "              total_matches+=1\n",
        "              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n",
        "              break\n",
        "\n",
        "        self.bleu_score+=total_matches/total_words\n",
        "\n",
        "    def result(self):\n",
        "        return self.bleu_score/BATCH_SIZE"
      ],
      "metadata": {
        "id": "Sn2pQG6frq4E"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_model.compile(\n",
        "    optimizer=Adam(1e-4),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[BLEU()],\n",
        "    run_eagerly=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "nyfhZadAsGCI"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = bahdanau_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=15,\n",
        "    validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5da6zVwPsYzq",
        "outputId": "cecc421a-5094-4fbd-a688-4027ae39586a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "2812/2812 [==============================] - 1014s 321ms/step - loss: 1.0310 - val_loss: 1.0754\n",
            "Epoch 2/15\n",
            "2812/2812 [==============================] - 825s 293ms/step - loss: 0.5372 - val_loss: 1.0082\n",
            "Epoch 3/15\n",
            "2812/2812 [==============================] - 865s 308ms/step - loss: 0.4861 - val_loss: 0.9377\n",
            "Epoch 4/15\n",
            "2812/2812 [==============================] - 831s 295ms/step - loss: 0.4453 - val_loss: 0.9000\n",
            "Epoch 5/15\n",
            "2812/2812 [==============================] - 824s 293ms/step - loss: 0.4143 - val_loss: 0.8747\n",
            "Epoch 6/15\n",
            "2812/2812 [==============================] - 825s 293ms/step - loss: 0.3907 - val_loss: 0.8464\n",
            "Epoch 7/15\n",
            "2812/2812 [==============================] - 838s 298ms/step - loss: 0.3685 - val_loss: 0.8299\n",
            "Epoch 8/15\n",
            "2812/2812 [==============================] - 824s 293ms/step - loss: 0.3480 - val_loss: 0.8021\n",
            "Epoch 9/15\n",
            "2812/2812 [==============================] - 823s 292ms/step - loss: 0.3297 - val_loss: 0.7809\n",
            "Epoch 10/15\n",
            "2812/2812 [==============================] - 820s 292ms/step - loss: 0.3130 - val_loss: 0.7815\n",
            "Epoch 11/15\n",
            "2812/2812 [==============================] - 821s 292ms/step - loss: 0.2978 - val_loss: 0.7598\n",
            "Epoch 12/15\n",
            "2812/2812 [==============================] - 819s 291ms/step - loss: 0.2831 - val_loss: 0.7511\n",
            "Epoch 13/15\n",
            "2812/2812 [==============================] - 818s 291ms/step - loss: 0.2689 - val_loss: 0.7436\n",
            "Epoch 14/15\n",
            "2812/2812 [==============================] - 818s 291ms/step - loss: 0.2554 - val_loss: 0.7228\n",
            "Epoch 15/15\n",
            "2812/2812 [==============================] - 824s 293ms/step - loss: 0.2429 - val_loss: 0.7207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_model.save('/content/drive/MyDrive/bahdanau_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my-CLtHifb_g",
        "outputId": "87dc8930-481d-4a7d-ef84-41e7c3234806"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loss Graph"
      ],
      "metadata": {
        "id": "Tm8auuonvf6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FTntNKzGvo8_",
        "outputId": "2e9eee7b-49e8-4421-9b99-a339268017af"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and Evalaution"
      ],
      "metadata": {
        "id": "MgsxM6FRu7Uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bahdanau_model.evaluate(val_dataset)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "RyAlVSFyslFZ",
        "outputId": "7b01accd-c431-4c87-bf43-c2c4947d7f11"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method BLEU.update_state of <__main__.BLEU object at 0x7a4180eb0730>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: not enough values to unpack (expected 2, got 0)\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method BLEU.update_state of <__main__.BLEU object at 0x7a4180eb0730>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: not enough values to unpack (expected 2, got 0)\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "    508/Unknown - 3604s 7s/step - loss: 0.5530 - bleu_2: 0.3521"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-8e70c2d9d2e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbahdanau_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m                         ):\n\u001b[1;32m   2199\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m                             logs = test_function_runner.run_step(\n\u001b[0m\u001b[1;32m   2201\u001b[0m                                 \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m                                 \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_shards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4000\u001b[0;31m         \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_or_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4001\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4002\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtest_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1970\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m                 \u001b[0;34m\"\"\"Runs a test execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1972\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1958\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4047\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4048\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4050\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1944\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0;31m# Updates stateful loss metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_test_function_exact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \"\"\"\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# The default implementation does not use `x`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mweighted_metric_obj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweighted_metric_objs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mobj_update_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 )\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-8fa25d7fea18>\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m               \u001b[0mtotal_matches\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mq\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensor_equals\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m   if (ops.Tensor._USE_EQUALITY and ops.executing_eagerly_outside_functions() and\n\u001b[0m\u001b[1;32m   2074\u001b[0m       (g is None or g.building_function)):\n\u001b[1;32m   2075\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5522\u001b[0m     \u001b[0mboolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutermost\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5523\u001b[0m   \"\"\"\n\u001b[0;32m-> 5524\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5525\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5526\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executing_eagerly\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2251\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2252\u001b[0m   \"\"\"Checks whether the current thread has eager execution enabled.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BLEU score achieved was quite low becuase of less training.***"
      ],
      "metadata": {
        "id": "WZrkEm2CuwxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n",
        "                                   french_vectorize_layer.get_vocabulary())}"
      ],
      "metadata": {
        "id": "ywy62Dm0thlA"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sentence):\n",
        "  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n",
        "  shifted_target='starttoken'\n",
        "\n",
        "  for i in range(FRENCH_SEQUENCE_LENGTH):\n",
        "    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n",
        "    output = bahdanau_model.predict([tokenized_english_sentence,tokenized_shifted_target])\n",
        "    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    current_word=index_to_word[french_word_index]\n",
        "    if current_word=='endtoken':\n",
        "      break\n",
        "    shifted_target+=' '+current_word\n",
        "  return shifted_target[11:]"
      ],
      "metadata": {
        "id": "D3O3VNS0ggp8"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation test"
      ],
      "metadata": {
        "id": "xw_AjIKqtnNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Google Translate: Qu'est-ce qui vous fait penser que ce n'est pas vrai ?\")\n",
        "translator('What makes you think that it is not true?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "eLi5EEJJtfsZ",
        "outputId": "5f03fada-b3c3-4972-b8b4-2c66933a452d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Translate: Qu'est-ce qui vous fait penser que ce n'est pas vrai ?\n",
            "1/1 [==============================] - 1s 722ms/step\n",
            "1/1 [==============================] - 1s 718ms/step\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "1/1 [==============================] - 1s 725ms/step\n",
            "1/1 [==============================] - 1s 713ms/step\n",
            "1/1 [==============================] - 1s 886ms/step\n",
            "1/1 [==============================] - 1s 989ms/step\n",
            "1/1 [==============================] - 1s 967ms/step\n",
            "1/1 [==============================] - 1s 873ms/step\n",
            "1/1 [==============================] - 1s 685ms/step\n",
            "1/1 [==============================] - 1s 714ms/step\n",
            "1/1 [==============================] - 1s 697ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'questce qui ne va pas que je ne pas être vrai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Google Translate: Avez-vous déjà regardé du football sous la pluie ?\")\n",
        "translator('Have you ever watched soccer under the rain?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "RkwpN7Totr_N",
        "outputId": "d65366e2-caa1-4d47-f012-ad2e7ac93811"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Translate: Avez-vous déjà regardé du football sous la pluie ?\n",
            "1/1 [==============================] - 1s 708ms/step\n",
            "1/1 [==============================] - 1s 694ms/step\n",
            "1/1 [==============================] - 1s 691ms/step\n",
            "1/1 [==============================] - 1s 829ms/step\n",
            "1/1 [==============================] - 1s 943ms/step\n",
            "1/1 [==============================] - 1s 910ms/step\n",
            "1/1 [==============================] - 1s 722ms/step\n",
            "1/1 [==============================] - 1s 702ms/step\n",
            "1/1 [==============================] - 1s 717ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'astu déjà vu la lettre à la bibliothèque'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Google Translate: Les grands arbres ne poussent pas facilement, plus les vents sont forts, plus les arbres sont forts\")\n",
        "translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "WNkcz7mKtufs",
        "outputId": "280b05ae-a677-448d-cefc-15ff171c7fce"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Translate: Les grands arbres ne poussent pas facilement, plus les vents sont forts, plus les arbres sont forts\n",
            "1/1 [==============================] - 1s 713ms/step\n",
            "1/1 [==============================] - 1s 720ms/step\n",
            "1/1 [==============================] - 1s 707ms/step\n",
            "1/1 [==============================] - 1s 698ms/step\n",
            "1/1 [==============================] - 1s 728ms/step\n",
            "1/1 [==============================] - 1s 756ms/step\n",
            "1/1 [==============================] - 1s 957ms/step\n",
            "1/1 [==============================] - 1s 988ms/step\n",
            "1/1 [==============================] - 1s 704ms/step\n",
            "1/1 [==============================] - 1s 699ms/step\n",
            "1/1 [==============================] - 1s 734ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'les gens ne sont pas la plus de la nuit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verdict"
      ],
      "metadata": {
        "id": "WzpQDu-vvG0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Longer translations accuracy is low because the dataset fed consists of short sentences, overall the BLEU score is low, more training is required with a faster GPU."
      ],
      "metadata": {
        "id": "okcEiER0vKv7"
      }
    }
  ]
}